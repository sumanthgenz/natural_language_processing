{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ast\n",
    "import re\n",
    "import copy\n",
    "import math\n",
    "import openpyxl\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "import csv\n",
    "import random\n",
    "import sklearn\n",
    "import tensorflow_text\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397\n",
      "3110\n",
      "27\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "request, intent, attributes = [], [], []\n",
    "\n",
    "# temp = pd.read_excel('/Users/sumanth.gurram/Desktop/en-itsm-zeroshot-attributes.xlsx')\n",
    "# numRows, numCols = temp.shape\n",
    "# numCols = numCols - 2\n",
    "# for index, row in temp.iterrows():\n",
    "#     request.append(row['English Utterance'])\n",
    "#     intent.append(row['Intent'])\n",
    "#     vec = row[2:]\n",
    "#     vec = vec.tolist()\n",
    "#     attributes.append(vec)\n",
    "\n",
    "def input(file):\n",
    "    data = json.load(open(file))['intents']\n",
    "    for each in data:\n",
    "        label = each['name']\n",
    "        for req in each['samples']:\n",
    "            r = req['utterance']\n",
    "            if r == 'wi-fi':\n",
    "                r = \"wireless access\"\n",
    "            r = r.replace(\"-\", \" \")\n",
    "            request.append(r)\n",
    "            intent.append(label)\n",
    "            attributes.append([0]*52)\n",
    "            \n",
    "            \n",
    "input('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/models/en-US-ITSM.json')\n",
    "# input('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/models/fr-FR-ITSM.json')\n",
    "# input('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/models/de-DE-ITSM.json')\n",
    "# input('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/models/en-US-HR.json')\n",
    "# input('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/models/fr-FR-HR.json')\n",
    "# input('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/models/de-DE-HR.json')\n",
    "# input('/Users/sumanth.gurram/Desktop/surf200-model.json')\n",
    "\n",
    "\n",
    "u2l = {}\n",
    "u2v = {}\n",
    "file = open('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/test-data/en-US-ITSM-test.txt', 'r') \n",
    "# file = open('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/test-data/fr-FR-ITSM-test.txt', 'r') \n",
    "# file = open('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/test-data/de-DE-ITSM.txt', 'r') \n",
    "# file = open('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/test-data/en-US-HR-test.txt', 'r') \n",
    "# file = open('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/test-data/fr-FR-HR-test.txt', 'r') \n",
    "# file = open('/Users/sumanth.gurram/Desktop/git/ml/nlu-tools/src/main/resources/f-measure/test-data/de-DE-HR.txt', 'r') \n",
    "# file = open('/Users/sumanth.gurram/Desktop/SURF-200-test.txt', 'r') \n",
    "\n",
    "\n",
    "Lines = file.readlines()\n",
    "Lines = Lines[1:]\n",
    "it, rq = [], []\n",
    "\n",
    "for line in Lines: \n",
    "    split = line.strip().split('\\t')\n",
    "    s = split[2]\n",
    "    tent = s.replace(\"sn_surf_200.\", \"\")\n",
    "    it.append(tent)\n",
    "    r = split[1]\n",
    "    if r == 'wi-fi':\n",
    "        r = \"wireless access\"\n",
    "    r = r.replace(\"-\", \" \")\n",
    "    rq.append(r)\n",
    "\n",
    "print(len(request))\n",
    "print(len(rq))\n",
    "print(len(Counter(intent)))\n",
    "print(len(Counter(it)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "rq[85] = \"incident ticket\"\n",
    "rq[1512] = \"incident ticket\"\n",
    "rq[365] = \"change request\"\n",
    "rq[385] = \"change request\"\n",
    "rq[875] = \"encryption\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KeyedVectors.load_word2vec_format(\n",
    "#     '/Users/sumanth.gurram/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667988982014136\n"
     ]
    }
   ],
   "source": [
    "# def ang(x,y):\n",
    "#     nx = np.linalg.norm(x)\n",
    "#     ny = np.linalg.norm(y)\n",
    "#     cos = np.dot(x, y)/(nx * ny)\n",
    "#     if cos > 1:\n",
    "#         cos = 1\n",
    "#     elif cos < -1:\n",
    "#         cos = -1\n",
    "#     return 1 - np.arccos(cos)/np.pi\n",
    "\n",
    "# vec = model[\"sultan\"]\n",
    "# vec2 = model[\"emperor\"]\n",
    "# print(ang(vec, vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_words = [[w for w in r.lower().split()] for r in request]\n",
    "rq_words = [[w for w in r.lower().split()] for r in rq]\n",
    "vectors = []\n",
    "vc = []\n",
    "\n",
    "for utt in request_words:\n",
    "#     temp = []\n",
    "#     for w in utt:\n",
    "#         try:\n",
    "#             temp.append(model[w])\n",
    "#         except:\n",
    "#             burner = 1\n",
    "#     if len(temp) == 0:\n",
    "#         print(utt)\n",
    "    temp = embed(utt)\n",
    "    vectors.append(np.average(temp, axis=0))\n",
    "\n",
    "count = 0\n",
    "for utt in rq_words:\n",
    "#     temp = []\n",
    "#     for w in utt:\n",
    "#         try:\n",
    "#             temp.append(model[w])\n",
    "#         except:\n",
    "#             burner = 1\n",
    "#     if len(temp) == 0:\n",
    "#         print(count)\n",
    "#         print(utt)\n",
    "    temp = embed(utt)\n",
    "    vc.append(np.average(temp, axis=0))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3110, 512)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectors).shape\n",
    "np.array(vc).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tents = Counter(intent)\n",
    "tts = Counter(it)\n",
    "combined = list(tents+tts)\n",
    "\n",
    "labelmap = {}\n",
    "for i in range(len(combined)):\n",
    "    labelmap[combined[i]] = i+1\n",
    "intentmap = []\n",
    "itmap = []\n",
    "\n",
    "for a in range(len(intent)):\n",
    "    intentmap.append(labelmap[intent[a]])\n",
    "    \n",
    "for b in range(len(it)):\n",
    "    itmap.append(labelmap[it[b]])\n",
    "    \n",
    "\n",
    "request = np.array(request)\n",
    "intent = np.array(intent)\n",
    "intentmap = np.array(intentmap)\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "rq = np.array(rq)\n",
    "it = np.array(it)\n",
    "itmap = np.array(itmap)\n",
    "vc = np.array(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 ... 27 27 27]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n"
     ]
    }
   ],
   "source": [
    "print(intentmap)\n",
    "print(list(Counter(intentmap)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "uttlab = {}\n",
    "uttvec = {}\n",
    "uttatt = {}\n",
    "\n",
    "for x in range(len(request)):\n",
    "    r = request[x]\n",
    "    i = intent[x]\n",
    "    v = vectors[x]\n",
    "    a = attributes[x]\n",
    "    if r not in uttlab:\n",
    "        uttlab[r] = i\n",
    "    if r not in uttvec:\n",
    "        uttvec[r] = np.array(v)\n",
    "    if r not in uttatt:\n",
    "        uttatt[r] = np.array(a)\n",
    "\n",
    "for x in range(len(rq)):\n",
    "    rr = rq[x]\n",
    "    ii = it[x]\n",
    "    vv = vc[x]\n",
    "    if rr not in u2l:\n",
    "        u2l[rr] = ii\n",
    "    if rr not in u2v:\n",
    "        u2v[rr] = np.array(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "bw = \"bow_guse_\"\n",
    "lg = \"en_\"\n",
    "# lg = \"fr_\"\n",
    "# lg = \"de_\"\n",
    "# ty = \"sf_\"\n",
    "ty = \"it_\"\n",
    "# ty = \"hr_\"\n",
    "c = bw + lg + ty\n",
    "with open(c + 'train_uttlab.pickle', 'wb') as handle:\n",
    "    pickle.dump(uttlab, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(c + 'train_uttvec.pickle', 'wb') as hd:\n",
    "    pickle.dump(uttvec, hd, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(c + 'train_uttatt.pickle', 'wb') as hd:\n",
    "    pickle.dump(uttatt, hd, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(c + 'test_uttlab.pickle', 'wb') as handle:\n",
    "    pickle.dump(u2l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(c + 'test_uttvec.pickle', 'wb') as hd:\n",
    "    pickle.dump(u2v, hd, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
