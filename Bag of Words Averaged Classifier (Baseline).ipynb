{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnx==1.7.0\n",
    "# # !pip install tensorflow==1.15.0\n",
    "# !pip install torch==1.4.0\n",
    "# !pip install onnx_tf==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# class BUModelDataLoader(Dataset):\n",
    "    \n",
    "#     def __init__(self, utt2LabelDictPath, utt2VectorDictPath):\n",
    "#         with open(utt2LabelDictPath, 'rb') as handle:\n",
    "#             self.utt2LabelDict = pickle.load(handle)\n",
    "#         with open(utt2VectorDictPath, 'rb') as handle:\n",
    "#             self.utt2VectorDict = pickle.load(handle)\n",
    "#         self.len = len(self.utt2LabelDict.keys())\n",
    "#         self.idx2Utt = {}\n",
    "        \n",
    "#         for idx, utt in enumerate(self.utt2LabelDict.keys()):\n",
    "#             self.idx2Utt[idx] = utt\n",
    "            \n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         utt = self.idx2Utt[idx]\n",
    "#         vec = self.utt2VectorDict[utt]\n",
    "#         lab = self.utt2LabelDict[utt]\n",
    "#         return vec, utt\n",
    "\n",
    "class BUModelDataLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, utt2LabelDictPath, utt2VectorDictPath, utt2AttDictPath):\n",
    "        assert(utt2LabelDictPath != None)\n",
    "        assert(utt2VectorDictPath != None)\n",
    "        assert(utt2AttDictPath != None)\n",
    "        try :\n",
    "            with open(utt2LabelDictPath, 'rb') as handle:\n",
    "                self.utt2LabelDict = pickle.load(handle)\n",
    "            with open(utt2VectorDictPath, 'rb') as handle:\n",
    "                self.utt2VectorDict = pickle.load(handle)\n",
    "            with open(utt2AttDictPath, 'rb') as handle:\n",
    "                self.utt2AttDict = pickle.load(handle)\n",
    "        except :\n",
    "            raise Exception('Invalid path')\n",
    "            \n",
    "        self.len = len(self.utt2LabelDict.keys())\n",
    "        self.idx2Utt = {}\n",
    "        self.lab2LabIdMap = {}\n",
    "        self.Labels = []\n",
    "        \n",
    "        for idx, utt in enumerate(self.utt2LabelDict.keys()):\n",
    "            self.idx2Utt[idx] = utt\n",
    "            self.Labels.append(self.utt2LabelDict[utt])\n",
    "        for labId, lab in enumerate(set(self.Labels)):\n",
    "            self.lab2LabIdMap[lab] = labId\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def getNumClasses(self):\n",
    "        return len(Counter(self.Labels))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        utt = self.idx2Utt[idx]\n",
    "        vec = self.utt2VectorDict[utt]\n",
    "        lab = self.utt2LabelDict[utt]\n",
    "        labId = self.lab2LabIdMap[lab]\n",
    "        if utt in self.utt2AttDict:\n",
    "            att = self.utt2AttDict[utt]\n",
    "        else:\n",
    "            att = [0]*52\n",
    "        return vec, utt, labId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters BASELINE\n",
    "input_size = 512\n",
    "hidden_size = 220\n",
    "num_classes = 27\n",
    "num_epochs = 25\n",
    "batch_size = 40\n",
    "learning_rate = 0.001\n",
    "\n",
    "# from onnx_tf.backend import prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397\n",
      "3094\n",
      "27\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#MNIST dataset \n",
    "# train_dataset = BUModelDataLoader('uttlab.npy', 'uttvec.npy')\n",
    "bw = \"bow_guse_\"\n",
    "lg = \"en_\"\n",
    "# lg = \"fr_\"\n",
    "# lg = \"de_\"\n",
    "# ty = \"sf_\"\n",
    "ty = \"it_\"\n",
    "# ty = \"hr_\"\n",
    "c = bw + lg + ty\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = BUModelDataLoader(c + 'train_uttlab.pickle', c + 'train_uttvec.pickle', c + 'train_uttatt.pickle') \n",
    "test_dataset = BUModelDataLoader(c +'test_uttlab.pickle', c + 'test_uttvec.pickle', c + 'train_uttatt.pickle') \n",
    "# print(len(Counter(list(train_dataset.lab2LabIdMap.values()))))\n",
    "# print(len(Counter(list(test_dataset.lab2LabIdMap.values()))))\n",
    "\n",
    "# comb = train_dataset.Labels + test_dataset.Labels\n",
    "# comb = list(Counter(comb))\n",
    "# newmap = {}\n",
    "# for i in range(len(comb)):\n",
    "#     newmap[comb[i]] = i\n",
    "    \n",
    "# train_dataset.lab2LabIdMap = newmap    \n",
    "# test_dataset.lab2LabIdMap = newmap    \n",
    "\n",
    "# train_dataset.lab2LabIdMap.update(test_dataset.lab2LabIdMap)\n",
    "# test_dataset.lab2LabIdMap = train_dataset.lab2LabIdMap\n",
    "\n",
    "\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n",
    "\n",
    "eval_train = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=4000, \n",
    "                                           shuffle=True)\n",
    "\n",
    "eval_test = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=4000, \n",
    "                                          shuffle=True)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(Counter(list(train_dataset.lab2LabIdMap.values()))))\n",
    "print(len(Counter(list(test_dataset.lab2LabIdMap.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my print job is stuck\n",
      "Can I see my ticket status\n",
      "(512,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6776776812427899"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(list(train_dataset.utt2AttDict.values())[0:5])\n",
    "# print(list(train_dataset.utt2AttDict.keys())[0:5])\n",
    "# print(list(train_dataset.utt2LabelDict.values())[0:5])\n",
    "\n",
    "def ang(x,y):\n",
    "    nx = np.linalg.norm(x)\n",
    "    ny = np.linalg.norm(y)\n",
    "    cos = np.dot(x, y)/(nx * ny)\n",
    "    if cos > 1:\n",
    "        cos = 1\n",
    "    elif cos < -1:\n",
    "        cos = -1\n",
    "    return 1 - np.arccos(cos)/np.pi\n",
    "ind1 = 800\n",
    "ind2 = 12\n",
    "print(list(train_dataset.utt2VectorDict.keys())[ind1])\n",
    "print(list(train_dataset.utt2VectorDict.keys())[ind2])\n",
    "vec1 = list(test_dataset.utt2VectorDict.values())[ind1]\n",
    "vec2 = list(test_dataset.utt2VectorDict.values())[ind2]\n",
    "print(vec1.shape)\n",
    "ang(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one = 46\n",
    "# two = 44\n",
    "# a = list(test_dataset.utt2VectorDict.values())[one]\n",
    "# b = list(test_dataset.utt2VectorDict.values())[two]\n",
    "# print(list(test_dataset.utt2VectorDict.keys())[one])\n",
    "# print(list(test_dataset.utt2VectorDict.keys())[two])\n",
    "# print(list(test_dataset.utt2LabelDict.values())[one])\n",
    "# print(list(test_dataset.utt2LabelDict.values())[two])\n",
    "# def ang(x,y):\n",
    "#     nx = np.linalg.norm(x)\n",
    "#     ny = np.linalg.norm(y)\n",
    "#     cos = np.dot(x, y)/(nx * ny)\n",
    "#     if cos > 1:\n",
    "#         cos = 1\n",
    "#     elif cos < -1:\n",
    "#         cos = -1\n",
    "#     return 1 - np.arccos(cos)/np.pi\n",
    "\n",
    "# print(ang(a, b))\n",
    "# print(list(test_dataset.utt2LabelDict.keys())[1:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pb(path_to_pb):\n",
    "    with tf.gfile.GFile(path_to_pb, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        return graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [5/35], Loss: 3.2800\n",
      "Epoch [1/25], Step [10/35], Loss: 3.2690\n",
      "Epoch [1/25], Step [15/35], Loss: 3.2535\n",
      "Epoch [1/25], Step [20/35], Loss: 3.2480\n",
      "Epoch [1/25], Step [25/35], Loss: 3.2181\n",
      "Epoch [1/25], Step [30/35], Loss: 3.2028\n",
      "Epoch [1/25], Step [35/35], Loss: 3.1647\n",
      "Epoch [2/25], Step [5/35], Loss: 3.2392\n",
      "Epoch [2/25], Step [10/35], Loss: 3.0859\n",
      "Epoch [2/25], Step [15/35], Loss: 3.1326\n",
      "Epoch [2/25], Step [20/35], Loss: 3.0863\n",
      "Epoch [2/25], Step [25/35], Loss: 3.1420\n",
      "Epoch [2/25], Step [30/35], Loss: 3.0754\n",
      "Epoch [2/25], Step [35/35], Loss: 3.0639\n",
      "Epoch [3/25], Step [5/35], Loss: 2.9330\n",
      "Epoch [3/25], Step [10/35], Loss: 3.0211\n",
      "Epoch [3/25], Step [15/35], Loss: 3.0100\n",
      "Epoch [3/25], Step [20/35], Loss: 3.0147\n",
      "Epoch [3/25], Step [25/35], Loss: 2.9705\n",
      "Epoch [3/25], Step [30/35], Loss: 2.9142\n",
      "Epoch [3/25], Step [35/35], Loss: 2.7991\n",
      "Epoch [4/25], Step [5/35], Loss: 2.8295\n",
      "Epoch [4/25], Step [10/35], Loss: 2.7488\n",
      "Epoch [4/25], Step [15/35], Loss: 2.6739\n",
      "Epoch [4/25], Step [20/35], Loss: 2.5533\n",
      "Epoch [4/25], Step [25/35], Loss: 2.6225\n",
      "Epoch [4/25], Step [30/35], Loss: 2.5764\n",
      "Epoch [4/25], Step [35/35], Loss: 2.4577\n",
      "Epoch [5/25], Step [5/35], Loss: 2.4691\n",
      "Epoch [5/25], Step [10/35], Loss: 2.5619\n",
      "Epoch [5/25], Step [15/35], Loss: 2.3287\n",
      "Epoch [5/25], Step [20/35], Loss: 2.3894\n",
      "Epoch [5/25], Step [25/35], Loss: 2.3289\n",
      "Epoch [5/25], Step [30/35], Loss: 2.1938\n",
      "Epoch [5/25], Step [35/35], Loss: 2.0213\n",
      "Epoch [6/25], Step [5/35], Loss: 2.0369\n",
      "Epoch [6/25], Step [10/35], Loss: 1.9898\n",
      "Epoch [6/25], Step [15/35], Loss: 1.9141\n",
      "Epoch [6/25], Step [20/35], Loss: 1.9409\n",
      "Epoch [6/25], Step [25/35], Loss: 1.9061\n",
      "Epoch [6/25], Step [30/35], Loss: 1.8175\n",
      "Epoch [6/25], Step [35/35], Loss: 1.7484\n",
      "Epoch [7/25], Step [5/35], Loss: 1.7290\n",
      "Epoch [7/25], Step [10/35], Loss: 1.6071\n",
      "Epoch [7/25], Step [15/35], Loss: 1.6738\n",
      "Epoch [7/25], Step [20/35], Loss: 1.6461\n",
      "Epoch [7/25], Step [25/35], Loss: 1.5761\n",
      "Epoch [7/25], Step [30/35], Loss: 1.4697\n",
      "Epoch [7/25], Step [35/35], Loss: 1.5261\n",
      "Epoch [8/25], Step [5/35], Loss: 1.4957\n",
      "Epoch [8/25], Step [10/35], Loss: 1.4181\n",
      "Epoch [8/25], Step [15/35], Loss: 1.6137\n",
      "Epoch [8/25], Step [20/35], Loss: 1.4750\n",
      "Epoch [8/25], Step [25/35], Loss: 1.4671\n",
      "Epoch [8/25], Step [30/35], Loss: 1.2326\n",
      "Epoch [8/25], Step [35/35], Loss: 1.3082\n",
      "Epoch [9/25], Step [5/35], Loss: 1.2377\n",
      "Epoch [9/25], Step [10/35], Loss: 1.2242\n",
      "Epoch [9/25], Step [15/35], Loss: 0.9656\n",
      "Epoch [9/25], Step [20/35], Loss: 1.1368\n",
      "Epoch [9/25], Step [25/35], Loss: 1.2366\n",
      "Epoch [9/25], Step [30/35], Loss: 1.1683\n",
      "Epoch [9/25], Step [35/35], Loss: 1.0015\n",
      "Epoch [10/25], Step [5/35], Loss: 1.2397\n",
      "Epoch [10/25], Step [10/35], Loss: 1.1141\n",
      "Epoch [10/25], Step [15/35], Loss: 1.1323\n",
      "Epoch [10/25], Step [20/35], Loss: 1.1482\n",
      "Epoch [10/25], Step [25/35], Loss: 1.0116\n",
      "Epoch [10/25], Step [30/35], Loss: 0.9013\n",
      "Epoch [10/25], Step [35/35], Loss: 0.9427\n",
      "Epoch [11/25], Step [5/35], Loss: 1.0269\n",
      "Epoch [11/25], Step [10/35], Loss: 1.0362\n",
      "Epoch [11/25], Step [15/35], Loss: 1.0343\n",
      "Epoch [11/25], Step [20/35], Loss: 1.0378\n",
      "Epoch [11/25], Step [25/35], Loss: 0.9828\n",
      "Epoch [11/25], Step [30/35], Loss: 0.7938\n",
      "Epoch [11/25], Step [35/35], Loss: 0.9279\n",
      "Epoch [12/25], Step [5/35], Loss: 0.8540\n",
      "Epoch [12/25], Step [10/35], Loss: 0.8808\n",
      "Epoch [12/25], Step [15/35], Loss: 1.0457\n",
      "Epoch [12/25], Step [20/35], Loss: 0.7201\n",
      "Epoch [12/25], Step [25/35], Loss: 0.7296\n",
      "Epoch [12/25], Step [30/35], Loss: 0.8956\n",
      "Epoch [12/25], Step [35/35], Loss: 0.9010\n",
      "Epoch [13/25], Step [5/35], Loss: 0.6834\n",
      "Epoch [13/25], Step [10/35], Loss: 0.8490\n",
      "Epoch [13/25], Step [15/35], Loss: 0.8669\n",
      "Epoch [13/25], Step [20/35], Loss: 0.7598\n",
      "Epoch [13/25], Step [25/35], Loss: 0.7448\n",
      "Epoch [13/25], Step [30/35], Loss: 0.7071\n",
      "Epoch [13/25], Step [35/35], Loss: 0.5890\n",
      "Epoch [14/25], Step [5/35], Loss: 0.8115\n",
      "Epoch [14/25], Step [10/35], Loss: 0.7175\n",
      "Epoch [14/25], Step [15/35], Loss: 0.7215\n",
      "Epoch [14/25], Step [20/35], Loss: 0.7913\n",
      "Epoch [14/25], Step [25/35], Loss: 0.6650\n",
      "Epoch [14/25], Step [30/35], Loss: 0.8251\n",
      "Epoch [14/25], Step [35/35], Loss: 0.4751\n",
      "Epoch [15/25], Step [5/35], Loss: 0.5672\n",
      "Epoch [15/25], Step [10/35], Loss: 0.6601\n",
      "Epoch [15/25], Step [15/35], Loss: 0.5537\n",
      "Epoch [15/25], Step [20/35], Loss: 0.6420\n",
      "Epoch [15/25], Step [25/35], Loss: 0.6833\n",
      "Epoch [15/25], Step [30/35], Loss: 0.4669\n",
      "Epoch [15/25], Step [35/35], Loss: 0.5713\n",
      "Epoch [16/25], Step [5/35], Loss: 0.5986\n",
      "Epoch [16/25], Step [10/35], Loss: 0.6336\n",
      "Epoch [16/25], Step [15/35], Loss: 0.5191\n",
      "Epoch [16/25], Step [20/35], Loss: 0.5648\n",
      "Epoch [16/25], Step [25/35], Loss: 0.4296\n",
      "Epoch [16/25], Step [30/35], Loss: 0.5403\n",
      "Epoch [16/25], Step [35/35], Loss: 0.4491\n",
      "Epoch [17/25], Step [5/35], Loss: 0.6775\n",
      "Epoch [17/25], Step [10/35], Loss: 0.4914\n",
      "Epoch [17/25], Step [15/35], Loss: 0.3769\n",
      "Epoch [17/25], Step [20/35], Loss: 0.4504\n",
      "Epoch [17/25], Step [25/35], Loss: 0.5567\n",
      "Epoch [17/25], Step [30/35], Loss: 0.3433\n",
      "Epoch [17/25], Step [35/35], Loss: 0.4670\n",
      "Epoch [18/25], Step [5/35], Loss: 0.4899\n",
      "Epoch [18/25], Step [10/35], Loss: 0.4109\n",
      "Epoch [18/25], Step [15/35], Loss: 0.5045\n",
      "Epoch [18/25], Step [20/35], Loss: 0.3675\n",
      "Epoch [18/25], Step [25/35], Loss: 0.5021\n",
      "Epoch [18/25], Step [30/35], Loss: 0.5724\n",
      "Epoch [18/25], Step [35/35], Loss: 0.3595\n",
      "Epoch [19/25], Step [5/35], Loss: 0.3896\n",
      "Epoch [19/25], Step [10/35], Loss: 0.4416\n",
      "Epoch [19/25], Step [15/35], Loss: 0.5721\n",
      "Epoch [19/25], Step [20/35], Loss: 0.4501\n",
      "Epoch [19/25], Step [25/35], Loss: 0.3451\n",
      "Epoch [19/25], Step [30/35], Loss: 0.4250\n",
      "Epoch [19/25], Step [35/35], Loss: 0.4993\n",
      "Epoch [20/25], Step [5/35], Loss: 0.3988\n",
      "Epoch [20/25], Step [10/35], Loss: 0.4009\n",
      "Epoch [20/25], Step [15/35], Loss: 0.3376\n",
      "Epoch [20/25], Step [20/35], Loss: 0.3986\n",
      "Epoch [20/25], Step [25/35], Loss: 0.3449\n",
      "Epoch [20/25], Step [30/35], Loss: 0.5090\n",
      "Epoch [20/25], Step [35/35], Loss: 0.3969\n",
      "Epoch [21/25], Step [5/35], Loss: 0.3709\n",
      "Epoch [21/25], Step [10/35], Loss: 0.5013\n",
      "Epoch [21/25], Step [15/35], Loss: 0.4365\n",
      "Epoch [21/25], Step [20/35], Loss: 0.2599\n",
      "Epoch [21/25], Step [25/35], Loss: 0.5539\n",
      "Epoch [21/25], Step [30/35], Loss: 0.3316\n",
      "Epoch [21/25], Step [35/35], Loss: 0.3833\n",
      "Epoch [22/25], Step [5/35], Loss: 0.4411\n",
      "Epoch [22/25], Step [10/35], Loss: 0.3868\n",
      "Epoch [22/25], Step [15/35], Loss: 0.4277\n",
      "Epoch [22/25], Step [20/35], Loss: 0.3273\n",
      "Epoch [22/25], Step [25/35], Loss: 0.2950\n",
      "Epoch [22/25], Step [30/35], Loss: 0.6367\n",
      "Epoch [22/25], Step [35/35], Loss: 0.3773\n",
      "Epoch [23/25], Step [5/35], Loss: 0.2725\n",
      "Epoch [23/25], Step [10/35], Loss: 0.2157\n",
      "Epoch [23/25], Step [15/35], Loss: 0.4860\n",
      "Epoch [23/25], Step [20/35], Loss: 0.3560\n",
      "Epoch [23/25], Step [25/35], Loss: 0.2366\n",
      "Epoch [23/25], Step [30/35], Loss: 0.3857\n",
      "Epoch [23/25], Step [35/35], Loss: 0.3579\n",
      "Epoch [24/25], Step [5/35], Loss: 0.3311\n",
      "Epoch [24/25], Step [10/35], Loss: 0.3138\n",
      "Epoch [24/25], Step [15/35], Loss: 0.3175\n",
      "Epoch [24/25], Step [20/35], Loss: 0.4045\n",
      "Epoch [24/25], Step [25/35], Loss: 0.2984\n",
      "Epoch [24/25], Step [30/35], Loss: 0.3492\n",
      "Epoch [24/25], Step [35/35], Loss: 0.6066\n",
      "Epoch [25/25], Step [5/35], Loss: 0.3296\n",
      "Epoch [25/25], Step [10/35], Loss: 0.2261\n",
      "Epoch [25/25], Step [15/35], Loss: 0.3021\n",
      "Epoch [25/25], Step [20/35], Loss: 0.2803\n",
      "Epoch [25/25], Step [25/35], Loss: 0.3016\n",
      "Epoch [25/25], Step [30/35], Loss: 0.2763\n",
      "Epoch [25/25], Step [35/35], Loss: 0.1499\n"
     ]
    }
   ],
   "source": [
    "###BASELINE\n",
    "###NUM CLASSES\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "\n",
    "if not os.path.exists('./ZS/'):\n",
    "    os.mkdir('./ZS/')\n",
    "\n",
    "if not os.path.exists('./ZSModels/'):\n",
    "    os.mkdir('./ZSModels/')    \n",
    "\n",
    "if not os.path.exists('./ZSGraphs/'):\n",
    "    os.mkdir('./ZSGraphs/')  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (vectors, utts, labId) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        vectors = vectors.to(device)\n",
    "\n",
    "        \n",
    "        outputs = model(vectors)\n",
    "        loss = criterion(outputs, labId)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 5 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "#             if epoch > 3.0:\n",
    "#                 title = './RNN/' + str(epoch+1) + \".\" + str(i+1) + '.onnx'\n",
    "#                 dummy_input = torch.rand(1, 1, 512)\n",
    "#                 dummy_output = model.emb(dummy_input)\n",
    "#                 torch.onnx.export(model, dummy_input, title, input_names=['test_input'], output_names=['test_output'])\n",
    "                                \n",
    "#                 graph_title = './RNNGraphs/' + str(epoch+1) + \".\" + str(i+1) + '.pb'\n",
    "#                 model_onnx = onnx.load(title)\n",
    "#                 tf_rep = prepare(model_onnx)\n",
    "#                 tf_rep.export_graph(graph_title)\n",
    "                \n",
    "#                 model_title = './RNNModels/' + str(epoch+1) + \".\" + str(i+1)\n",
    "#                 tf_graph = load_pb(graph_title)\n",
    "                \n",
    "#                 with tf.Session(graph=tf_graph) as sess:\n",
    "#                     sess.run(tf.global_variables_initializer())\n",
    "#                     ops = tf.get_default_graph().get_operations() \n",
    "#                     sess.run(tf.get_default_graph().get_operation_by_name('init'))\n",
    "\n",
    "#                     ou_tensor = tf_graph.get_tensor_by_name('test_output:0')\n",
    "#                     in_tensor = tf_graph.get_tensor_by_name('test_input:0')\n",
    "\n",
    "#                     tf.saved_model.simple_save(sess, model_title, inputs={'input': in_tensor}, outputs={'output': ou_tensor})\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(train_dataset.utt2VectorDict.keys())[0:8])\n",
    "print(list(train_dataset.utt2LabelDict.values())[0:8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 0.04713113896597199\n",
      "KNN: 0.047416992822691864\n"
     ]
    }
   ],
   "source": [
    "###BASELINE\n",
    "###NUM CLASSES\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "vector, atts, labId = [], [], []\n",
    "vec, att, lab = [], [], []\n",
    "with torch.no_grad():\n",
    "    for i, (vec, att, lab) in enumerate(eval_test):\n",
    "        outputs = model(vec.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    a = f1_score(lab, predicted, average='weighted')\n",
    "    print(\"Trained: \" + str(a))\n",
    "    \n",
    "    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "vector, atts, labId = [], [], []\n",
    "vec, att, lab = [], [], []\n",
    "with torch.no_grad():\n",
    "    for i, (vectors, atts, labId) in enumerate(eval_train):\n",
    "        neighbor = KNeighborsClassifier(n_neighbors=1)\n",
    "        neighbor.fit(vectors.numpy(), labId.numpy())\n",
    "    for i, (vec, att, lab) in enumerate(eval_test):\n",
    "        predicted = neighbor.predict(vec.numpy())\n",
    "    b = f1_score(lab, predicted, average='weighted')\n",
    "    print(\"KNN: \" + str(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"BoW_Models/\" + c + str(a)\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
